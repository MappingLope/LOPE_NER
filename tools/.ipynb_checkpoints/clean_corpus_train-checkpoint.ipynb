{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de frases: 17483\n",
      "Con LOC o PER: 3878\n",
      "Sin LOC ni PER: 13605\n",
      "Corpus final: 7300 frases guardadas en balanced_corpus.txt\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def load_sentences(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read().strip()\n",
    "    # Cada frase separada por doble salto de lÃ­nea\n",
    "    sentences = text.split(\"\\n\\n\")\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "def save_sentences(sentences, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\\n\".join(sentences) + \"\\n\")\n",
    "\n",
    "def contains_loc_or_per(sentence):\n",
    "    return any(tag in sentence for tag in [\"B-LOC\", \"I-LOC\", \"B-PER\", \"I-PER\"])\n",
    "\n",
    "def main():\n",
    "    files = [\"train.txt\", \"dev.txt\", \"test.txt\"]\n",
    "\n",
    "    sentences = []\n",
    "    for file in files:\n",
    "        sentences.extend(load_sentences(file))\n",
    "\n",
    "    # Separar por presencia de LOC o PER\n",
    "    tagged_sentences = [s for s in sentences if contains_loc_or_per(s)]\n",
    "    non_tagged_sentences = [s for s in sentences if not contains_loc_or_per(s)]\n",
    "\n",
    "    print(f\"Total de frases: {len(sentences)}\")\n",
    "    print(f\"Con LOC o PER: {len(tagged_sentences)}\")\n",
    "    print(f\"Sin LOC ni PER: {len(non_tagged_sentences)}\")\n",
    "\n",
    "    target_total = 7300\n",
    "    n_tagged = len(tagged_sentences)\n",
    "\n",
    "    if n_tagged >= target_total:\n",
    "        final_sentences = random.sample(tagged_sentences, target_total)\n",
    "    else:\n",
    "        n_non_tagged_needed = target_total - n_tagged\n",
    "        n_non_tagged_needed = min(n_non_tagged_needed, len(non_tagged_sentences))\n",
    "        sampled_non_tagged = random.sample(non_tagged_sentences, n_non_tagged_needed)\n",
    "        final_sentences = tagged_sentences + sampled_non_tagged\n",
    "\n",
    "    random.shuffle(final_sentences)\n",
    "    save_sentences(final_sentences, \"balanced_corpus.txt\")\n",
    "\n",
    "    print(f\"Corpus final: {len(final_sentences)} frases guardadas en balanced_corpus.txt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
