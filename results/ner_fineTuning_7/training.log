2025-11-30 21:00:10,158 ----------------------------------------------------------------------------------------------------
2025-11-30 21:00:10,160 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024, padding_idx=1)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSdpaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=5, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2025-11-30 21:00:10,161 ----------------------------------------------------------------------------------------------------
2025-11-30 21:00:10,161 Corpus: 39893 train + 4220 dev + 4979 test sentences
2025-11-30 21:00:10,161 ----------------------------------------------------------------------------------------------------
2025-11-30 21:00:10,162 Train:  39893 sentences
2025-11-30 21:00:10,162         (train_with_dev=False, train_with_test=False)
2025-11-30 21:00:10,162 ----------------------------------------------------------------------------------------------------
2025-11-30 21:00:10,162 Training Params:
2025-11-30 21:00:10,163  - learning_rate: "5e-06" 
2025-11-30 21:00:10,163  - mini_batch_size: "4"
2025-11-30 21:00:10,163  - max_epochs: "10"
2025-11-30 21:00:10,163  - shuffle: "True"
2025-11-30 21:00:10,164 ----------------------------------------------------------------------------------------------------
2025-11-30 21:00:10,164 Plugins:
2025-11-30 21:00:10,164  - LinearScheduler | warmup_fraction: '0.1'
2025-11-30 21:00:10,164 ----------------------------------------------------------------------------------------------------
2025-11-30 21:00:10,165 Final evaluation on model after last epoch (final-model.pt)
2025-11-30 21:00:10,165  - metric: "('micro avg', 'f1-score')"
2025-11-30 21:00:10,165 ----------------------------------------------------------------------------------------------------
2025-11-30 21:00:10,166 Computation:
2025-11-30 21:00:10,166  - compute on device: cuda:0
2025-11-30 21:00:10,166  - embedding storage: gpu
2025-11-30 21:00:10,166 ----------------------------------------------------------------------------------------------------
2025-11-30 21:00:10,167 Model training base path: "ner_fineTuning_2"
2025-11-30 21:00:10,167 ----------------------------------------------------------------------------------------------------
2025-11-30 21:00:10,167 ----------------------------------------------------------------------------------------------------
2025-11-30 21:04:57,919 epoch 1 - iter 997/9974 - loss 0.60601036 - time (sec): 287.75 - samples/sec: 268.89 - lr: 0.000000 - momentum: 0.000000
2025-11-30 21:09:42,626 epoch 1 - iter 1994/9974 - loss 0.31502591 - time (sec): 572.46 - samples/sec: 267.47 - lr: 0.000001 - momentum: 0.000000
2025-11-30 21:14:27,041 epoch 1 - iter 2991/9974 - loss 0.21706007 - time (sec): 856.87 - samples/sec: 265.78 - lr: 0.000001 - momentum: 0.000000
2025-11-30 21:19:09,315 epoch 1 - iter 3988/9974 - loss 0.16675299 - time (sec): 1139.15 - samples/sec: 266.95 - lr: 0.000002 - momentum: 0.000000
2025-11-30 21:23:50,183 epoch 1 - iter 4985/9974 - loss 0.13643299 - time (sec): 1420.01 - samples/sec: 267.09 - lr: 0.000002 - momentum: 0.000000
2025-11-30 21:28:30,093 epoch 1 - iter 5982/9974 - loss 0.11579982 - time (sec): 1699.92 - samples/sec: 267.58 - lr: 0.000003 - momentum: 0.000000
2025-11-30 21:33:09,734 epoch 1 - iter 6979/9974 - loss 0.10089424 - time (sec): 1979.56 - samples/sec: 267.88 - lr: 0.000003 - momentum: 0.000000
2025-11-30 21:37:49,245 epoch 1 - iter 7976/9974 - loss 0.08992633 - time (sec): 2259.08 - samples/sec: 268.38 - lr: 0.000004 - momentum: 0.000000
2025-11-30 21:42:29,042 epoch 1 - iter 8973/9974 - loss 0.08108447 - time (sec): 2538.87 - samples/sec: 268.74 - lr: 0.000004 - momentum: 0.000000
2025-11-30 21:47:09,924 epoch 1 - iter 9970/9974 - loss 0.07397153 - time (sec): 2819.76 - samples/sec: 269.47 - lr: 0.000005 - momentum: 0.000000
2025-11-30 21:47:10,889 ----------------------------------------------------------------------------------------------------
2025-11-30 21:47:10,889 EPOCH 1 done: loss 0.0739 - lr: 0.000005
2025-11-30 21:48:09,949 DEV : loss 0.011261017061769962 - f1-score (micro avg)  0.9404
2025-11-30 21:48:10,086 ----------------------------------------------------------------------------------------------------
2025-11-30 21:52:49,114 epoch 2 - iter 997/9974 - loss 0.01052105 - time (sec): 279.03 - samples/sec: 272.16 - lr: 0.000005 - momentum: 0.000000
2025-11-30 21:57:29,476 epoch 2 - iter 1994/9974 - loss 0.00921117 - time (sec): 559.39 - samples/sec: 272.11 - lr: 0.000005 - momentum: 0.000000
2025-11-30 22:02:08,520 epoch 2 - iter 2991/9974 - loss 0.00848787 - time (sec): 838.43 - samples/sec: 272.75 - lr: 0.000005 - momentum: 0.000000
2025-11-30 22:06:46,955 epoch 2 - iter 3988/9974 - loss 0.00897529 - time (sec): 1116.87 - samples/sec: 273.21 - lr: 0.000005 - momentum: 0.000000
2025-11-30 22:11:24,777 epoch 2 - iter 4985/9974 - loss 0.00887542 - time (sec): 1394.69 - samples/sec: 272.21 - lr: 0.000005 - momentum: 0.000000
2025-11-30 22:16:03,087 epoch 2 - iter 5982/9974 - loss 0.00911551 - time (sec): 1673.00 - samples/sec: 273.12 - lr: 0.000005 - momentum: 0.000000
2025-11-30 22:20:41,372 epoch 2 - iter 6979/9974 - loss 0.00901215 - time (sec): 1951.28 - samples/sec: 273.72 - lr: 0.000005 - momentum: 0.000000
2025-11-30 22:25:19,622 epoch 2 - iter 7976/9974 - loss 0.00881249 - time (sec): 2229.53 - samples/sec: 273.04 - lr: 0.000005 - momentum: 0.000000
2025-11-30 22:29:59,088 epoch 2 - iter 8973/9974 - loss 0.00845775 - time (sec): 2509.00 - samples/sec: 272.73 - lr: 0.000005 - momentum: 0.000000
2025-11-30 22:34:37,256 epoch 2 - iter 9970/9974 - loss 0.00850637 - time (sec): 2787.17 - samples/sec: 272.61 - lr: 0.000004 - momentum: 0.000000
2025-11-30 22:34:38,215 ----------------------------------------------------------------------------------------------------
2025-11-30 22:34:38,215 EPOCH 2 done: loss 0.0085 - lr: 0.000004
2025-11-30 22:34:41,956 DEV : loss 0.011352176778018475 - f1-score (micro avg)  0.9404
2025-11-30 22:34:42,088 ----------------------------------------------------------------------------------------------------
2025-11-30 22:39:21,629 epoch 3 - iter 997/9974 - loss 0.00562963 - time (sec): 279.54 - samples/sec: 271.83 - lr: 0.000004 - momentum: 0.000000
2025-11-30 22:43:59,945 epoch 3 - iter 1994/9974 - loss 0.00711679 - time (sec): 557.85 - samples/sec: 272.91 - lr: 0.000004 - momentum: 0.000000
2025-11-30 22:48:38,531 epoch 3 - iter 2991/9974 - loss 0.00620800 - time (sec): 836.44 - samples/sec: 273.28 - lr: 0.000004 - momentum: 0.000000
2025-11-30 22:53:17,147 epoch 3 - iter 3988/9974 - loss 0.00607752 - time (sec): 1115.06 - samples/sec: 272.67 - lr: 0.000004 - momentum: 0.000000
2025-11-30 22:57:55,276 epoch 3 - iter 4985/9974 - loss 0.00624165 - time (sec): 1393.19 - samples/sec: 272.12 - lr: 0.000004 - momentum: 0.000000
2025-11-30 23:02:33,531 epoch 3 - iter 5982/9974 - loss 0.00618645 - time (sec): 1671.44 - samples/sec: 272.91 - lr: 0.000004 - momentum: 0.000000
2025-11-30 23:07:13,385 epoch 3 - iter 6979/9974 - loss 0.00594988 - time (sec): 1951.29 - samples/sec: 272.52 - lr: 0.000004 - momentum: 0.000000
2025-11-30 23:11:51,608 epoch 3 - iter 7976/9974 - loss 0.00590140 - time (sec): 2229.52 - samples/sec: 272.91 - lr: 0.000004 - momentum: 0.000000
2025-11-30 23:16:29,972 epoch 3 - iter 8973/9974 - loss 0.00601583 - time (sec): 2507.88 - samples/sec: 273.03 - lr: 0.000004 - momentum: 0.000000
2025-11-30 23:21:08,432 epoch 3 - iter 9970/9974 - loss 0.00594104 - time (sec): 2786.34 - samples/sec: 272.69 - lr: 0.000004 - momentum: 0.000000
2025-11-30 23:21:09,411 ----------------------------------------------------------------------------------------------------
2025-11-30 23:21:09,412 EPOCH 3 done: loss 0.0059 - lr: 0.000004
2025-11-30 23:21:13,215 DEV : loss 0.011391700245440006 - f1-score (micro avg)  0.9404
2025-11-30 23:21:13,352 ----------------------------------------------------------------------------------------------------
2025-11-30 23:25:53,016 epoch 4 - iter 997/9974 - loss 0.00397835 - time (sec): 279.66 - samples/sec: 269.13 - lr: 0.000004 - momentum: 0.000000
2025-11-30 23:30:31,710 epoch 4 - iter 1994/9974 - loss 0.00366728 - time (sec): 558.36 - samples/sec: 273.67 - lr: 0.000004 - momentum: 0.000000
2025-11-30 23:35:10,417 epoch 4 - iter 2991/9974 - loss 0.00381862 - time (sec): 837.06 - samples/sec: 272.89 - lr: 0.000004 - momentum: 0.000000
2025-11-30 23:39:49,233 epoch 4 - iter 3988/9974 - loss 0.00389473 - time (sec): 1115.88 - samples/sec: 272.34 - lr: 0.000004 - momentum: 0.000000
2025-11-30 23:44:27,785 epoch 4 - iter 4985/9974 - loss 0.00385245 - time (sec): 1394.43 - samples/sec: 272.47 - lr: 0.000004 - momentum: 0.000000
2025-11-30 23:49:05,862 epoch 4 - iter 5982/9974 - loss 0.00381038 - time (sec): 1672.51 - samples/sec: 272.29 - lr: 0.000004 - momentum: 0.000000
2025-11-30 23:53:45,752 epoch 4 - iter 6979/9974 - loss 0.00391939 - time (sec): 1952.40 - samples/sec: 271.81 - lr: 0.000004 - momentum: 0.000000
2025-11-30 23:58:24,535 epoch 4 - iter 7976/9974 - loss 0.00416031 - time (sec): 2231.18 - samples/sec: 272.04 - lr: 0.000003 - momentum: 0.000000
2025-12-01 00:03:02,973 epoch 4 - iter 8973/9974 - loss 0.00410194 - time (sec): 2509.62 - samples/sec: 272.34 - lr: 0.000003 - momentum: 0.000000
2025-12-01 00:07:41,505 epoch 4 - iter 9970/9974 - loss 0.00408385 - time (sec): 2788.15 - samples/sec: 272.51 - lr: 0.000003 - momentum: 0.000000
2025-12-01 00:07:42,458 ----------------------------------------------------------------------------------------------------
2025-12-01 00:07:42,467 EPOCH 4 done: loss 0.0041 - lr: 0.000003
2025-12-01 00:07:46,706 DEV : loss 0.01145333331078291 - f1-score (micro avg)  0.9404
2025-12-01 00:07:46,877 ----------------------------------------------------------------------------------------------------
2025-12-01 00:12:27,205 epoch 5 - iter 997/9974 - loss 0.00151998 - time (sec): 280.33 - samples/sec: 278.91 - lr: 0.000003 - momentum: 0.000000
2025-12-01 00:17:05,529 epoch 5 - iter 1994/9974 - loss 0.00223165 - time (sec): 558.65 - samples/sec: 276.33 - lr: 0.000003 - momentum: 0.000000
2025-12-01 00:21:44,123 epoch 5 - iter 2991/9974 - loss 0.00261103 - time (sec): 837.24 - samples/sec: 274.35 - lr: 0.000003 - momentum: 0.000000
2025-12-01 00:26:22,681 epoch 5 - iter 3988/9974 - loss 0.00278460 - time (sec): 1115.80 - samples/sec: 274.21 - lr: 0.000003 - momentum: 0.000000
2025-12-01 00:31:01,146 epoch 5 - iter 4985/9974 - loss 0.00277426 - time (sec): 1394.27 - samples/sec: 273.00 - lr: 0.000003 - momentum: 0.000000
2025-12-01 00:35:40,188 epoch 5 - iter 5982/9974 - loss 0.00281573 - time (sec): 1673.31 - samples/sec: 273.23 - lr: 0.000003 - momentum: 0.000000
2025-12-01 00:40:19,939 epoch 5 - iter 6979/9974 - loss 0.00291106 - time (sec): 1953.06 - samples/sec: 272.88 - lr: 0.000003 - momentum: 0.000000
2025-12-01 00:44:58,458 epoch 5 - iter 7976/9974 - loss 0.00298566 - time (sec): 2231.58 - samples/sec: 273.12 - lr: 0.000003 - momentum: 0.000000
2025-12-01 00:49:36,551 epoch 5 - iter 8973/9974 - loss 0.00312269 - time (sec): 2509.67 - samples/sec: 272.72 - lr: 0.000003 - momentum: 0.000000
2025-12-01 00:54:14,919 epoch 5 - iter 9970/9974 - loss 0.00308016 - time (sec): 2788.04 - samples/sec: 272.52 - lr: 0.000003 - momentum: 0.000000
2025-12-01 00:54:15,889 ----------------------------------------------------------------------------------------------------
2025-12-01 00:54:15,889 EPOCH 5 done: loss 0.0031 - lr: 0.000003
2025-12-01 00:54:19,634 DEV : loss 0.0115328598767519 - f1-score (micro avg)  0.9404
2025-12-01 00:54:19,766 ----------------------------------------------------------------------------------------------------
2025-12-01 00:58:59,428 epoch 6 - iter 997/9974 - loss 0.00232644 - time (sec): 279.66 - samples/sec: 268.78 - lr: 0.000003 - momentum: 0.000000
2025-12-01 01:03:37,696 epoch 6 - iter 1994/9974 - loss 0.00190335 - time (sec): 557.93 - samples/sec: 271.64 - lr: 0.000003 - momentum: 0.000000
2025-12-01 01:08:16,205 epoch 6 - iter 2991/9974 - loss 0.00184672 - time (sec): 836.44 - samples/sec: 273.27 - lr: 0.000003 - momentum: 0.000000
2025-12-01 01:12:54,493 epoch 6 - iter 3988/9974 - loss 0.00163219 - time (sec): 1114.72 - samples/sec: 271.97 - lr: 0.000003 - momentum: 0.000000
2025-12-01 01:17:33,402 epoch 6 - iter 4985/9974 - loss 0.00181678 - time (sec): 1393.63 - samples/sec: 273.09 - lr: 0.000003 - momentum: 0.000000
2025-12-01 01:22:11,726 epoch 6 - iter 5982/9974 - loss 0.00177914 - time (sec): 1671.96 - samples/sec: 272.85 - lr: 0.000002 - momentum: 0.000000
2025-12-01 01:26:51,479 epoch 6 - iter 6979/9974 - loss 0.00191528 - time (sec): 1951.71 - samples/sec: 272.28 - lr: 0.000002 - momentum: 0.000000
2025-12-01 01:31:30,516 epoch 6 - iter 7976/9974 - loss 0.00193731 - time (sec): 2230.75 - samples/sec: 272.15 - lr: 0.000002 - momentum: 0.000000
2025-12-01 01:36:08,755 epoch 6 - iter 8973/9974 - loss 0.00197653 - time (sec): 2508.99 - samples/sec: 272.10 - lr: 0.000002 - momentum: 0.000000
2025-12-01 01:40:47,195 epoch 6 - iter 9970/9974 - loss 0.00198850 - time (sec): 2787.43 - samples/sec: 272.61 - lr: 0.000002 - momentum: 0.000000
2025-12-01 01:40:48,171 ----------------------------------------------------------------------------------------------------
2025-12-01 01:40:48,172 EPOCH 6 done: loss 0.0020 - lr: 0.000002
2025-12-01 01:40:51,971 DEV : loss 0.011609550565481186 - f1-score (micro avg)  0.9404
2025-12-01 01:40:52,098 ----------------------------------------------------------------------------------------------------
2025-12-01 01:45:31,893 epoch 7 - iter 997/9974 - loss 0.00200520 - time (sec): 279.79 - samples/sec: 269.21 - lr: 0.000002 - momentum: 0.000000
2025-12-01 01:50:10,127 epoch 7 - iter 1994/9974 - loss 0.00211309 - time (sec): 558.03 - samples/sec: 274.55 - lr: 0.000002 - momentum: 0.000000
2025-12-01 01:54:48,688 epoch 7 - iter 2991/9974 - loss 0.00164622 - time (sec): 836.59 - samples/sec: 272.77 - lr: 0.000002 - momentum: 0.000000
2025-12-01 01:59:27,472 epoch 7 - iter 3988/9974 - loss 0.00144787 - time (sec): 1115.37 - samples/sec: 272.47 - lr: 0.000002 - momentum: 0.000000
2025-12-01 02:04:06,159 epoch 7 - iter 4985/9974 - loss 0.00130233 - time (sec): 1394.06 - samples/sec: 272.70 - lr: 0.000002 - momentum: 0.000000
2025-12-01 02:08:44,987 epoch 7 - iter 5982/9974 - loss 0.00118778 - time (sec): 1672.89 - samples/sec: 272.34 - lr: 0.000002 - momentum: 0.000000
2025-12-01 02:13:25,257 epoch 7 - iter 6979/9974 - loss 0.00123597 - time (sec): 1953.16 - samples/sec: 272.60 - lr: 0.000002 - momentum: 0.000000
2025-12-01 02:18:04,193 epoch 7 - iter 7976/9974 - loss 0.00130453 - time (sec): 2232.09 - samples/sec: 272.48 - lr: 0.000002 - momentum: 0.000000
2025-12-01 02:22:42,701 epoch 7 - iter 8973/9974 - loss 0.00133652 - time (sec): 2510.60 - samples/sec: 272.46 - lr: 0.000002 - momentum: 0.000000
2025-12-01 02:27:22,067 epoch 7 - iter 9970/9974 - loss 0.00133751 - time (sec): 2789.97 - samples/sec: 272.33 - lr: 0.000002 - momentum: 0.000000
2025-12-01 02:27:23,035 ----------------------------------------------------------------------------------------------------
2025-12-01 02:27:23,035 EPOCH 7 done: loss 0.0013 - lr: 0.000002
2025-12-01 02:27:26,784 DEV : loss 0.011708787642419338 - f1-score (micro avg)  0.9404
2025-12-01 02:27:26,920 ----------------------------------------------------------------------------------------------------
2025-12-01 02:32:06,405 epoch 8 - iter 997/9974 - loss 0.00113846 - time (sec): 279.48 - samples/sec: 274.70 - lr: 0.000002 - momentum: 0.000000
2025-12-01 02:36:45,264 epoch 8 - iter 1994/9974 - loss 0.00096632 - time (sec): 558.34 - samples/sec: 275.25 - lr: 0.000002 - momentum: 0.000000
2025-12-01 02:41:23,835 epoch 8 - iter 2991/9974 - loss 0.00092426 - time (sec): 836.91 - samples/sec: 274.25 - lr: 0.000002 - momentum: 0.000000
2025-12-01 02:46:02,328 epoch 8 - iter 3988/9974 - loss 0.00092291 - time (sec): 1115.40 - samples/sec: 273.91 - lr: 0.000001 - momentum: 0.000000
2025-12-01 02:50:40,576 epoch 8 - iter 4985/9974 - loss 0.00085118 - time (sec): 1393.65 - samples/sec: 273.14 - lr: 0.000001 - momentum: 0.000000
2025-12-01 02:55:19,092 epoch 8 - iter 5982/9974 - loss 0.00079270 - time (sec): 1672.17 - samples/sec: 273.34 - lr: 0.000001 - momentum: 0.000000
2025-12-01 02:59:58,406 epoch 8 - iter 6979/9974 - loss 0.00074980 - time (sec): 1951.48 - samples/sec: 273.14 - lr: 0.000001 - momentum: 0.000000
2025-12-01 03:04:36,474 epoch 8 - iter 7976/9974 - loss 0.00077559 - time (sec): 2229.55 - samples/sec: 272.54 - lr: 0.000001 - momentum: 0.000000
2025-12-01 03:09:14,767 epoch 8 - iter 8973/9974 - loss 0.00080988 - time (sec): 2507.84 - samples/sec: 272.43 - lr: 0.000001 - momentum: 0.000000
2025-12-01 03:13:53,019 epoch 8 - iter 9970/9974 - loss 0.00087933 - time (sec): 2786.10 - samples/sec: 272.73 - lr: 0.000001 - momentum: 0.000000
2025-12-01 03:13:53,980 ----------------------------------------------------------------------------------------------------
2025-12-01 03:13:53,980 EPOCH 8 done: loss 0.0009 - lr: 0.000001
2025-12-01 03:13:57,732 DEV : loss 0.011771687306463718 - f1-score (micro avg)  0.9404
2025-12-01 03:13:57,864 ----------------------------------------------------------------------------------------------------
2025-12-01 03:18:37,194 epoch 9 - iter 997/9974 - loss 0.00068286 - time (sec): 279.33 - samples/sec: 272.72 - lr: 0.000001 - momentum: 0.000000
2025-12-01 03:23:15,680 epoch 9 - iter 1994/9974 - loss 0.00053057 - time (sec): 557.81 - samples/sec: 272.57 - lr: 0.000001 - momentum: 0.000000
2025-12-01 03:27:54,123 epoch 9 - iter 2991/9974 - loss 0.00080388 - time (sec): 836.26 - samples/sec: 273.63 - lr: 0.000001 - momentum: 0.000000
2025-12-01 03:32:32,359 epoch 9 - iter 3988/9974 - loss 0.00089788 - time (sec): 1114.49 - samples/sec: 274.21 - lr: 0.000001 - momentum: 0.000000
2025-12-01 03:37:10,750 epoch 9 - iter 4985/9974 - loss 0.00078522 - time (sec): 1392.88 - samples/sec: 273.44 - lr: 0.000001 - momentum: 0.000000
2025-12-01 03:41:49,285 epoch 9 - iter 5982/9974 - loss 0.00076300 - time (sec): 1671.42 - samples/sec: 273.76 - lr: 0.000001 - momentum: 0.000000
2025-12-01 03:46:28,997 epoch 9 - iter 6979/9974 - loss 0.00078937 - time (sec): 1951.13 - samples/sec: 273.71 - lr: 0.000001 - momentum: 0.000000
2025-12-01 03:51:07,372 epoch 9 - iter 7976/9974 - loss 0.00087627 - time (sec): 2229.51 - samples/sec: 273.40 - lr: 0.000001 - momentum: 0.000000
2025-12-01 03:55:45,632 epoch 9 - iter 8973/9974 - loss 0.00084264 - time (sec): 2507.77 - samples/sec: 273.24 - lr: 0.000001 - momentum: 0.000000
2025-12-01 04:00:24,077 epoch 9 - iter 9970/9974 - loss 0.00084129 - time (sec): 2786.21 - samples/sec: 272.71 - lr: 0.000001 - momentum: 0.000000
2025-12-01 04:00:25,045 ----------------------------------------------------------------------------------------------------
2025-12-01 04:00:25,046 EPOCH 9 done: loss 0.0008 - lr: 0.000001
2025-12-01 04:00:28,803 DEV : loss 0.011798680759966373 - f1-score (micro avg)  0.9404
2025-12-01 04:00:28,934 ----------------------------------------------------------------------------------------------------
2025-12-01 04:05:08,614 epoch 10 - iter 997/9974 - loss 0.00022596 - time (sec): 279.68 - samples/sec: 266.69 - lr: 0.000001 - momentum: 0.000000
2025-12-01 04:09:46,821 epoch 10 - iter 1994/9974 - loss 0.00018418 - time (sec): 557.88 - samples/sec: 268.18 - lr: 0.000000 - momentum: 0.000000
2025-12-01 04:14:25,350 epoch 10 - iter 2991/9974 - loss 0.00021553 - time (sec): 836.41 - samples/sec: 270.91 - lr: 0.000000 - momentum: 0.000000
2025-12-01 04:19:03,467 epoch 10 - iter 3988/9974 - loss 0.00032603 - time (sec): 1114.53 - samples/sec: 272.08 - lr: 0.000000 - momentum: 0.000000
2025-12-01 04:23:41,586 epoch 10 - iter 4985/9974 - loss 0.00036618 - time (sec): 1392.65 - samples/sec: 271.49 - lr: 0.000000 - momentum: 0.000000
2025-12-01 04:28:19,491 epoch 10 - iter 5982/9974 - loss 0.00046170 - time (sec): 1670.55 - samples/sec: 271.55 - lr: 0.000000 - momentum: 0.000000
2025-12-01 04:32:59,168 epoch 10 - iter 6979/9974 - loss 0.00052982 - time (sec): 1950.23 - samples/sec: 271.70 - lr: 0.000000 - momentum: 0.000000
2025-12-01 04:37:37,593 epoch 10 - iter 7976/9974 - loss 0.00050790 - time (sec): 2228.66 - samples/sec: 272.33 - lr: 0.000000 - momentum: 0.000000
2025-12-01 04:42:16,132 epoch 10 - iter 8973/9974 - loss 0.00049155 - time (sec): 2507.19 - samples/sec: 272.33 - lr: 0.000000 - momentum: 0.000000
2025-12-01 04:46:54,452 epoch 10 - iter 9970/9974 - loss 0.00049141 - time (sec): 2785.52 - samples/sec: 272.81 - lr: 0.000000 - momentum: 0.000000
2025-12-01 04:46:55,403 ----------------------------------------------------------------------------------------------------
2025-12-01 04:46:55,403 EPOCH 10 done: loss 0.0005 - lr: 0.000000
2025-12-01 04:46:59,165 DEV : loss 0.011811768636107445 - f1-score (micro avg)  0.9404
2025-12-01 04:47:01,866 ----------------------------------------------------------------------------------------------------
2025-12-01 04:47:01,869 Testing using last state of model ...
2025-12-01 04:48:15,555 
Results:
- F-score (micro) 0.9501
- F-score (macro) 0.9501
- Accuracy 0.905

By class:
              precision    recall  f1-score   support

         LOC     0.9409    0.9595    0.9501       913

   micro avg     0.9409    0.9595    0.9501       913
   macro avg     0.9409    0.9595    0.9501       913
weighted avg     0.9409    0.9595    0.9501       913

2025-12-01 04:48:15,555 ----------------------------------------------------------------------------------------------------
